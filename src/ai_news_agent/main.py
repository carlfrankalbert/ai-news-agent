#!/usr/bin/env python3
"""
AI News Agent MVP
==================
Samler AI-verktÃ¸y-mentions fra Hacker News og rangerer dem med Claude.

Bruk:
    python main.py                    # KjÃ¸r full pipeline
    python main.py --collect-only     # Bare samle data
    python main.py --analyze-only     # Bare analyser (krever eksisterende data)
    python main.py --days 30          # Override antall dager
"""
import argparse
import asyncio

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenv not installed, skip (will use system env vars)
    pass

from typing import List, Dict
from pathlib import Path
import json
from datetime import datetime, timedelta

from .collectors.hackernews import collect_ai_mentions
from .collectors.github import collect_github_trending
from .analyzer import analyze_with_claude, validate_rankings, add_trends_to_rankings
from .config import LOOKBACK_DAYS, OUTPUT_DIR
from .utils import get_period_string, save_output, load_cached_posts




async def run_collection(days: int = LOOKBACK_DAYS) -> List[Dict]:
    """KjÃ¸r datainnsamling fra alle kilder."""
    print(f"ğŸ“¡ Samler data fra Hacker News (siste {days} dager)...")
    hn_posts = await collect_ai_mentions(days_back=days)
    print(f"âœ… Fant {len(hn_posts)} AI-relaterte HN posts")
    
    print(f"ğŸ“¡ Samler data fra GitHub Trending (siste {days} dager)...")
    github_repos = await collect_github_trending(days_back=days, max_results=100)
    print(f"âœ… Fant {len(github_repos)} AI-relaterte GitHub repos")
    
    # Kombiner og sorter
    all_posts = hn_posts + github_repos
    all_posts.sort(key=lambda x: x["points"], reverse=True)
    
    print(f"ğŸ“Š Totalt {len(all_posts)} AI-relaterte items fra alle kilder")
    if all_posts:
        print(f"   Topp item: [{all_posts[0]['points']} pts] {all_posts[0]['title'][:50]}...")
    
    return all_posts


def run_analysis(posts: list[dict], period: str) -> dict:
    """KjÃ¸r Claude-analyse pÃ¥ innsamlet data."""
    print(f"\nğŸ¤– Analyserer {len(posts)} posts med Claude...")
    
    rankings = analyze_with_claude(posts, period)
    
    # Valider output
    is_valid, issues = validate_rankings(rankings)
    if not is_valid:
        print(f"âš ï¸  Valideringsproblemer:")
        for issue in issues:
            print(f"   - {issue}")
    else:
        print("âœ… Rankings validert OK")
    
    return rankings


def print_summary(rankings: dict):
    """Print en lesbar oppsummering av resultatene."""
    print("\n" + "="*60)
    print("ğŸ“Š AI VERKTÃ˜Y-RANKING")
    print("="*60)
    
    if "summary" in rankings:
        print(f"\nğŸ“ Oppsummering: {rankings['summary']}")
    
    for cat in rankings.get("categories", []):
        print(f"\nğŸ† {cat['name']}")
        print("-" * 40)
        
        medals = {"gold": "ğŸ¥‡", "silver": "ğŸ¥ˆ", "bronze": "ğŸ¥‰"}
        
        for item in cat.get("top3", []):
            medal = medals.get(item.get("medal", ""), "  ")
            name = item.get("name", "?")
            provider = item.get("provider", "")
            reason = item.get("short_reason", "")
            
            # Vis trend hvis tilgjengelig
            trend = item.get("trend", {})
            trend_str = ""
            if trend.get("status"):
                status = trend["status"]
                status_emoji = {
                    "new": "âœ¨",
                    "rising": "ğŸ“ˆ",
                    "falling": "ğŸ“‰",
                    "stable": "â¡ï¸"
                }.get(status, "")
                
                change = trend.get("rank_change")
                if change is not None and change != 0:
                    trend_str = f" {status_emoji} {'+' if change > 0 else ''}{change}"
                elif status == "new":
                    trend_str = f" {status_emoji} Nytt"
                elif status == "stable" and trend.get("previous_rank"):
                    trend_str = f" {status_emoji} Uendret (var #{trend['previous_rank']})"
            
            print(f"{medal} {name} ({provider}){trend_str}")
            print(f"   {reason}")
    
    if rankings.get("new_and_noteworthy"):
        print(f"\nâœ¨ Nytt & spennende:")
        print("-" * 40)
        for item in rankings["new_and_noteworthy"]:
            print(f"â€¢ {item['name']} ({item.get('provider', '')}) - {item.get('short_reason', '')}")


async def main():
    parser = argparse.ArgumentParser(description="AI News Agent MVP")
    parser.add_argument("--collect-only", action="store_true", help="Bare samle data, ikke analyser")
    parser.add_argument("--analyze-only", action="store_true", help="Bare analyser eksisterende data")
    parser.add_argument("--days", type=int, default=LOOKBACK_DAYS, help="Antall dager tilbake")
    parser.add_argument("--no-cache", action="store_true", help="Ignorer cached data")
    args = parser.parse_args()
    
    period = get_period_string()
    print(f"ğŸš€ AI News Agent - Periode: {period}")
    print(f"   Lookback: {args.days} dager")
    
    # Steg 1: Samle data
    if args.analyze_only:
        posts = load_cached_posts(period)
        if not posts:
            print("âŒ Ingen cached data funnet. KjÃ¸r uten --analyze-only fÃ¸rst.")
            return
        print(f"ğŸ“‚ Lastet {len(posts)} cached posts")
    else:
        posts = await run_collection(days=args.days)
        
        # Cache rÃ¥data
        raw_file = save_output(posts, f"raw_posts_{period}.json")
        print(f"ğŸ’¾ RÃ¥data lagret: {raw_file}")
        
        if args.collect_only:
            print("\nâœ… Ferdig (collect-only mode)")
            return
    
    # Steg 2: Analyser med Claude
    rankings = run_analysis(posts, period)
    
    # Check if analysis failed
    if rankings.get("error"):
        print(f"\nâŒ Analyse feilet: {rankings.get('error')}")
        print("ğŸ’¡ PrÃ¸ver Ã¥ bruke forrige mÃ¥neds data hvis tilgjengelig...")
        
        # Try to use previous month's data as fallback
        from datetime import datetime, timedelta
        try:
            year, month = map(int, period.split("-"))
            prev_date = datetime(year, month, 1) - timedelta(days=1)
            prev_period = prev_date.strftime("%Y-%m")
            prev_file = Path(OUTPUT_DIR) / f"rankings_{prev_period}.json"
            
            if prev_file.exists():
                with open(prev_file) as f:
                    prev_rankings = json.load(f)
                print(f"âœ… Bruker data fra {prev_period} som fallback")
                rankings = prev_rankings
                rankings["period"] = period  # Update period
                rankings["generated_at"] = datetime.now().isoformat()
            else:
                print("âš ï¸  Ingen forrige mÃ¥neds data tilgjengelig")
        except Exception as e:
            print(f"âš ï¸  Kunne ikke laste forrige mÃ¥neds data: {e}")
    
    # Steg 2.5: Legg til trend-analyse (sammenlign med forrige mÃ¥ned)
    print("\nğŸ“Š Analyserer trender (sammenligner med forrige mÃ¥ned)...")
    rankings = add_trends_to_rankings(rankings)
    if rankings.get("trend_analysis", {}).get("has_previous_data"):
        prev_period = rankings["trend_analysis"]["previous_period"]
        print(f"âœ… Sammenlignet med {prev_period}")
    else:
        print("â„¹ï¸  Ingen forrige mÃ¥neds data funnet (fÃ¸rste kjÃ¸ring?)")
    
    # Steg 3: Lagre output
    output_file = save_output(rankings, f"rankings_{period}.json")
    print(f"ğŸ’¾ Rankings lagret: {output_file}")
    
    # Steg 4: Print oppsummering
    print_summary(rankings)
    
    print(f"\nâœ… Ferdig! Se {output_file} for full JSON.")


if __name__ == "__main__":
    asyncio.run(main())
